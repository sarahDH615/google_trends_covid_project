{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Abbrev</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Ala.</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Ariz.</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Ark.</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>Calif.</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>Colo.</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Conn.</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>Del.</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>D.C.</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>Fla.</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Ga.</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>Ill.</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>Ind.</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>Kans.</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Ky.</td>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>La.</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>Maine</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State  Abbrev Code\n",
       "0                Alabama    Ala.   AL\n",
       "1                 Alaska  Alaska   AK\n",
       "2                Arizona   Ariz.   AZ\n",
       "3               Arkansas    Ark.   AR\n",
       "4             California  Calif.   CA\n",
       "5               Colorado   Colo.   CO\n",
       "6            Connecticut   Conn.   CT\n",
       "7               Delaware    Del.   DE\n",
       "8   District of Columbia    D.C.   DC\n",
       "9                Florida    Fla.   FL\n",
       "10               Georgia     Ga.   GA\n",
       "11                Hawaii  Hawaii   HI\n",
       "12                 Idaho   Idaho   ID\n",
       "13              Illinois    Ill.   IL\n",
       "14               Indiana    Ind.   IN\n",
       "15                  Iowa    Iowa   IA\n",
       "16                Kansas   Kans.   KS\n",
       "17              Kentucky     Ky.   KY\n",
       "18             Louisiana     La.   LA\n",
       "19                 Maine   Maine   ME"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../statesAbbrev.csv'\n",
    "statesAbbrev_df = pd.read_csv(path)\n",
    "statesAbbrev_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list for state codes\n",
    "state_codes = [x for x in statesAbbrev_df['Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df dict to hold the state dfs, reading in the dfs\n",
    "states_df_dict = {}\n",
    "for x in range(10, 20):\n",
    "    path = f'../states_data/US-{state_codes[x]}_cat_data.csv'\n",
    "    states_df_dict[f'{state_codes[x]}_data_df'] = [pd.read_csv(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['GA_data_df', 'HI_data_df', 'ID_data_df', 'IL_data_df', 'IN_data_df', 'IA_data_df', 'KS_data_df', 'KY_data_df', 'LA_data_df', 'ME_data_df'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting the keys (ie df names)\n",
    "states_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>autos</th>\n",
       "      <th>beauty_fitness</th>\n",
       "      <th>books_lit</th>\n",
       "      <th>action_adventure</th>\n",
       "      <th>campaigns_elections</th>\n",
       "      <th>celebs</th>\n",
       "      <th>discrimination</th>\n",
       "      <th>entertainment_media</th>\n",
       "      <th>...</th>\n",
       "      <th>mobiles</th>\n",
       "      <th>online_vids</th>\n",
       "      <th>scifi_fantasy</th>\n",
       "      <th>sport_news</th>\n",
       "      <th>tv_shows</th>\n",
       "      <th>voice_vid_chat</th>\n",
       "      <th>weather</th>\n",
       "      <th>covid_cases</th>\n",
       "      <th>stay_at_home</th>\n",
       "      <th>mass_gathering_ban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>85</td>\n",
       "      <td>68</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>85</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>85</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>85</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>89</td>\n",
       "      <td>75</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>79</td>\n",
       "      <td>46</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>78</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>79</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>79</td>\n",
       "      <td>63</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>87</td>\n",
       "      <td>77</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>81</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>80</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  arts_entertainment  autos  beauty_fitness  books_lit  \\\n",
       "0  2019-01-06                  85     68              83         72   \n",
       "1  2019-01-13                  85     71              88         85   \n",
       "2  2019-01-20                  85     73              85         82   \n",
       "3  2019-01-27                  89     75              87         85   \n",
       "4  2019-02-03                  83     73              83         80   \n",
       "5  2019-02-10                  80     69              78         78   \n",
       "6  2019-02-17                  84     72              84         72   \n",
       "7  2019-02-24                  87     77              85         84   \n",
       "8  2019-03-03                  86     76              84         83   \n",
       "9  2019-03-10                  81     74              82         71   \n",
       "\n",
       "   action_adventure  campaigns_elections  celebs  discrimination  \\\n",
       "0                57                    0      61              15   \n",
       "1                72                    0      61              17   \n",
       "2                64                    0      56              16   \n",
       "3                63                    0      69              22   \n",
       "4                59                    0      56              20   \n",
       "5                54                    0      54              25   \n",
       "6                60                    0      72              19   \n",
       "7                57                    0      60              25   \n",
       "8                56                    0      52              42   \n",
       "9                53                    0      53              15   \n",
       "\n",
       "   entertainment_media  ...  mobiles  online_vids  scifi_fantasy  sport_news  \\\n",
       "0                   83  ...       55           77             63          76   \n",
       "1                   85  ...       57           85             48          67   \n",
       "2                   81  ...       57           91             61          69   \n",
       "3                   75  ...       59           90             53          70   \n",
       "4                   69  ...       54           79             46          85   \n",
       "5                   70  ...       55           78             48          52   \n",
       "6                   79  ...       60           80             50          52   \n",
       "7                   70  ...       57           77             56          54   \n",
       "8                   66  ...       58           74             48          54   \n",
       "9                   63  ...       54           80             46          61   \n",
       "\n",
       "   tv_shows  voice_vid_chat  weather  covid_cases  stay_at_home  \\\n",
       "0        82              65       51          NaN         False   \n",
       "1        85              48       64          NaN         False   \n",
       "2        84              64       69          NaN         False   \n",
       "3        85              79      100          NaN         False   \n",
       "4        84              65       54          NaN         False   \n",
       "5        79              63       63          NaN         False   \n",
       "6        79              63       74          NaN         False   \n",
       "7        81              77       63          NaN         False   \n",
       "8        94              70       78          NaN         False   \n",
       "9        80              60       56          NaN         False   \n",
       "\n",
       "   mass_gathering_ban  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "5               False  \n",
       "6               False  \n",
       "7               False  \n",
       "8               False  \n",
       "9               False  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test printing a df\n",
    "print(state_codes[10])\n",
    "states_df_dict[f'{state_codes[10]}_data_df'][0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(states_df_dict[f'{state_codes[10]}_data_df'][0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_for_max = [x for x in col_names if x not in ['time', 'covid_cases', 'stay_at_home', 'mass_gathering_ban']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_list = list(states_df_dict[f'{state_codes[11]}_data_df'][0]['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-01-06',\n",
       " '2019-01-13',\n",
       " '2019-01-20',\n",
       " '2019-01-27',\n",
       " '2019-02-03',\n",
       " '2019-02-10',\n",
       " '2019-02-17',\n",
       " '2019-02-24',\n",
       " '2019-03-03',\n",
       " '2019-03-10',\n",
       " '2019-03-17',\n",
       " '2019-03-24',\n",
       " '2019-03-31',\n",
       " '2019-04-07',\n",
       " '2019-04-14',\n",
       " '2019-04-21',\n",
       " '2019-04-28',\n",
       " '2019-05-05',\n",
       " '2019-05-12',\n",
       " '2019-05-19',\n",
       " '2019-05-26',\n",
       " '2019-06-02',\n",
       " '2019-06-09',\n",
       " '2019-06-16',\n",
       " '2019-06-23',\n",
       " '2019-06-30',\n",
       " '2019-07-07',\n",
       " '2019-07-14',\n",
       " '2019-07-21',\n",
       " '2019-07-28',\n",
       " '2019-08-04',\n",
       " '2019-08-11',\n",
       " '2019-08-18',\n",
       " '2019-08-25',\n",
       " '2019-09-01',\n",
       " '2019-09-08',\n",
       " '2019-09-15',\n",
       " '2019-09-22',\n",
       " '2019-09-29',\n",
       " '2019-10-06',\n",
       " '2019-10-13',\n",
       " '2019-10-20',\n",
       " '2019-10-27',\n",
       " '2019-11-03',\n",
       " '2019-11-10',\n",
       " '2019-11-17',\n",
       " '2019-11-24',\n",
       " '2019-12-01',\n",
       " '2019-12-08',\n",
       " '2019-12-15',\n",
       " '2019-12-22',\n",
       " '2019-12-29',\n",
       " '2020-01-05',\n",
       " '2020-01-12',\n",
       " '2020-01-19',\n",
       " '2020-01-26',\n",
       " '2020-02-02',\n",
       " '2020-02-09',\n",
       " '2020-02-16',\n",
       " '2020-02-23',\n",
       " '2020-03-01',\n",
       " '2020-03-08',\n",
       " '2020-03-15',\n",
       " '2020-03-22',\n",
       " '2020-03-29',\n",
       " '2020-04-05',\n",
       " '2020-04-12',\n",
       " '2020-04-19',\n",
       " '2020-04-26',\n",
       " '2020-05-03',\n",
       " '2020-05-10',\n",
       " '2020-05-17',\n",
       " '2020-05-24',\n",
       " '2020-05-31',\n",
       " '2020-06-07',\n",
       " '2020-06-14',\n",
       " '2020-06-21',\n",
       " '2020-06-28',\n",
       " '2020-07-05',\n",
       " '2020-07-12',\n",
       " '2020-07-19',\n",
       " '2020-07-26',\n",
       " '2020-08-02',\n",
       " '2020-08-09',\n",
       " '2020-08-16',\n",
       " '2020-08-23',\n",
       " '2020-08-30',\n",
       " '2020-09-06',\n",
       " '2020-09-13',\n",
       " '2020-09-20',\n",
       " '2020-09-27',\n",
       " '2020-10-04',\n",
       " '2020-10-11',\n",
       " '2020-10-18',\n",
       " '2020-10-25',\n",
       " '2020-11-01',\n",
       " '2020-11-08',\n",
       " '2020-11-15',\n",
       " '2020-11-22',\n",
       " '2020-11-29',\n",
       " '2020-12-06',\n",
       " '2020-12-13',\n",
       " '2020-12-20']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_per_col_dict = {}\n",
    "for x in range(0, len(col_names_for_max)):\n",
    "    for y in range(0, len(states_df_dict[f'{state_codes[10]}_data_df'][0])):\n",
    "        if states_df_dict[f'{state_codes[10]}_data_df'][0].iloc[y, x+1] == states_df_dict[f'{state_codes[10]}_data_df'][0][col_names_for_max[x]].max():\n",
    "            max_per_col_dict[f'{col_names_for_max[x]}'] = (times_list[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_per_col_df = pd.DataFrame({'max_date': list(max_per_col_dict.values()), 'cat': list(max_per_col_dict.keys())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_per_col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df_dict[f'{state_codes[10]}_data_df'].append(max_per_col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_date</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>arts_entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>beauty_fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>books_lit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>action_adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>campaigns_elections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>celebs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>discrimination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>entertainment_media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>games_systems_consoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>health_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>infectious_diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>law_enf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>lottos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>mobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>online_vids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>scifi_fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>sport_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>tv_shows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>voice_vid_chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      max_date                     cat\n",
       "0   2019-05-05      arts_entertainment\n",
       "1   2019-09-08                   autos\n",
       "2   2020-06-07          beauty_fitness\n",
       "3   2019-04-28               books_lit\n",
       "4   2020-10-25        action_adventure\n",
       "5   2020-11-01     campaigns_elections\n",
       "6   2020-11-01                  celebs\n",
       "7   2020-06-21          discrimination\n",
       "8   2020-03-22     entertainment_media\n",
       "9   2020-11-08  games_systems_consoles\n",
       "10  2020-04-19             health_news\n",
       "11  2020-03-15     infectious_diseases\n",
       "12  2020-06-14                 law_enf\n",
       "13  2019-03-24                  lottos\n",
       "14  2019-09-08                 mobiles\n",
       "15  2020-08-23             online_vids\n",
       "16  2019-08-25           scifi_fantasy\n",
       "17  2019-12-15              sport_news\n",
       "18  2019-05-05                tv_shows\n",
       "19  2019-08-04          voice_vid_chat\n",
       "20  2019-01-27                 weather"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_df_dict[f'{state_codes[10]}_data_df'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_col_dates(ind_num):\n",
    "    max_per_col_dict = {}\n",
    "    for x in range(0, len(col_names_for_max)):\n",
    "        for y in range(0, len(states_df_dict[f'{state_codes[ind_num]}_data_df'][0])):\n",
    "            # x+1 here because column 0 in the list is a cat, but col 0 on the df is 'time', so moving over index by one to get correct col\n",
    "            if states_df_dict[f'{state_codes[ind_num]}_data_df'][0].iloc[y, x+1] == states_df_dict[f'{state_codes[ind_num]}_data_df'][0][col_names_for_max[x]].max():\n",
    "                max_per_col_dict[f'{col_names_for_max[x]}'] = (times_list[y])\n",
    "    max_per_col_df = pd.DataFrame({'max_date': max_per_col_dict.values(), 'cat': max_per_col_dict.keys()})\n",
    "    states_df_dict[f'{state_codes[ind_num]}_data_df'].append(max_per_col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      max_date                     cat\n",
      "0   2019-05-05      arts_entertainment\n",
      "1   2019-09-08                   autos\n",
      "2   2020-06-07          beauty_fitness\n",
      "3   2019-04-28               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2020-03-22     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-04-19             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-06-14                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2020-08-23             online_vids\n",
      "16  2019-08-25           scifi_fantasy\n",
      "17  2019-12-15              sport_news\n",
      "18  2019-05-05                tv_shows\n",
      "19  2019-08-04          voice_vid_chat\n",
      "20  2019-01-27                 weather\n",
      "                                             max_date  \\\n",
      "0   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "1   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "2   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "3   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "4   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "5   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "6   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "7   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "8   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "9   (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "10  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "11  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "12  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "13  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "14  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "15  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "16  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "17  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "18  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "19  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "20  (2019-12-22, 2019-09-08, 2019-07-21, 2020-09-1...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "                                             max_date  \\\n",
      "0   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "1   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "2   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "3   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "4   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "5   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "6   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "7   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "8   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "9   (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "10  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "11  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "12  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "13  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "14  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "15  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "16  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "17  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "18  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "19  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "20  (2019-12-22, 2019-09-08, 2020-05-17, 2020-02-2...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "                                             max_date  \\\n",
      "0   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "1   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "2   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "3   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "4   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "5   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "6   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "7   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "8   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "9   (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "10  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "11  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "12  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "13  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "14  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "15  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "16  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "17  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "18  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "19  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "20  (2019-02-24, 2019-09-08, 2019-12-29, 2019-04-2...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             max_date  \\\n",
      "0   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "1   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "2   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "3   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "4   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "5   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "6   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "7   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "8   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "9   (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "10  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "11  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "12  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "13  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "14  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "15  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "16  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "17  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "18  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "19  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "20  (2019-08-18, 2019-09-01, 2020-05-17, 2019-04-1...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "                                             max_date  \\\n",
      "0   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "1   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "2   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "3   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "4   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "5   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "6   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "7   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "8   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "9   (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "10  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "11  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "12  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "13  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "14  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "15  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "16  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "17  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "18  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "19  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "20  (2019-02-24, 2020-06-07, 2020-05-17, 2019-04-2...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "                                             max_date  \\\n",
      "0   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "1   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "2   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "3   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "4   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "5   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "6   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "7   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "8   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "9   (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "10  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "11  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "12  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "13  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "14  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "15  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "16  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "17  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "18  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "19  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "20  (2019-02-24, 2019-09-08, 2019-02-17, 2019-04-2...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "                                             max_date  \\\n",
      "0   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "1   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "2   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "3   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "4   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "5   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "6   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "7   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "8   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "9   (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "10  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "11  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "12  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "13  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "14  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "15  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "16  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "17  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "18  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "19  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "20  (2019-10-20, 2019-09-01, 2020-02-23, 2020-02-2...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             max_date  \\\n",
      "0   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "1   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "2   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "3   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "4   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "5   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "6   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "7   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "8   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "9   (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "10  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "11  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "12  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "13  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "14  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "15  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "16  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "17  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "18  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "19  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "20  (2019-03-31, 2019-09-01, 2020-05-17, 2019-04-2...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "                                             max_date  \\\n",
      "0   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "1   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "2   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "3   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "4   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "5   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "6   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "7   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "8   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "9   (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "10  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "11  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "12  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "13  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "14  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "15  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "16  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "17  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "18  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "19  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "20  (2020-03-29, 2019-09-01, 2020-05-03, 2019-04-2...   \n",
      "\n",
      "                                                  cat  \n",
      "0   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "1   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "2   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "3   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "4   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "5   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "6   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "7   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "8   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "9   (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "10  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "11  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "12  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "13  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "14  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "15  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "16  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "17  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "18  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "19  (arts_entertainment, autos, beauty_fitness, bo...  \n",
      "20  (arts_entertainment, autos, beauty_fitness, bo...  \n"
     ]
    }
   ],
   "source": [
    "for x in range(10, 20):\n",
    "    get_max_col_dates(x)\n",
    "    print(states_df_dict[f'{state_codes[x]}_data_df'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_merge_list = [states_df_dict[f'{state_codes[x]}_data_df'][1] for x in range(10,20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(for_merge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10, 20):\n",
    "    states_df_dict[f'{state_codes[x]}_data_df'][1].rename(columns={'max_date': f'{state_codes[x]}_max_date'}, \n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-06a7952041b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m combo_df = reduce(lambda left,right: pd.merge(left,right,on=['cat'],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                             how='outer'), for_merge_list)\n\u001b[1;32m      3\u001b[0m \u001b[0mcombo_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-06a7952041b1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(left, right)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m combo_df = reduce(lambda left,right: pd.merge(left,right,on=['cat'],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                             how='outer'), for_merge_list)\n\u001b[1;32m      3\u001b[0m \u001b[0mcombo_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    860\u001b[0m             )\n\u001b[1;32m    861\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_join_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;34m\"\"\" return the join indexers \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         return _get_join_indexers(\n\u001b[0m\u001b[1;32m    841\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m     )\n\u001b[0;32m-> 1311\u001b[0;31m     \u001b[0mzipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m     \u001b[0mllab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzipped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;31m# get left & right join labels and num. of levels at each location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m     mapped = (\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0m_factorize_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_factorize_keys\u001b[0;34m(lk, rk, sort)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m     \u001b[0mllab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m     \u001b[0mrlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable.pyx\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Factorizer.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_labels\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict_keys'"
     ]
    }
   ],
   "source": [
    "combo_df = reduce(lambda left,right: pd.merge(left,right,on=['cat'],\n",
    "                                            how='outer'), for_merge_list)\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(combo_df.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = combo_df[cols]\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
